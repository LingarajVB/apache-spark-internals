<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Apache Spark"><link href=https://books.japila.pl/apache-spark-internals/storage/BlockManager/ rel=canonical><meta name=author content="Jacek Laskowski"><link rel="shortcut icon" href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.0.2"><title>BlockManager - The Internals of Apache Spark</title><link rel=stylesheet href=../../assets/stylesheets/main.38780c08.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f72e892.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-5","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#blockmanager class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-header-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> The Internals of Apache Spark </span> <span class="md-header-nav__topic md-ellipsis"> BlockManager </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class="md-tabs__link md-tabs__link--active"> Home </a> </li> <li class=md-tabs__item> <a href=../../tools/spark-shell/ class=md-tabs__link> Tools </a> </li> <li class=md-tabs__item> <a href=../../rdd/ class=md-tabs__link> RDD </a> </li> <li class=md-tabs__item> <a href=../../metrics/ class=md-tabs__link> Metrics </a> </li> <li class=md-tabs__item> <a href=../../demo/diskblockmanager-and-block-data/ class=md-tabs__link> Demos </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Welcome </a> </li> <li class=md-nav__item> <a href=../../overview/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../../SparkEnv/ class=md-nav__link> SparkEnv </a> </li> <li class=md-nav__item> <a href=../../SparkConf/ class=md-nav__link> SparkConf </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5 type=checkbox id=nav-1-5> <label class=md-nav__link for=nav-1-5> SparkContext <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SparkContext data-md-level=2> <label class=md-nav__title for=nav-1-5> <span class="md-nav__icon md-icon"></span> SparkContext </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../SparkContext/ class=md-nav__link> SparkContext </a> </li> <li class=md-nav__item> <a href=../../spark-SparkContext-creating-instance-internals/ class=md-nav__link> Creating SparkContext </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-logging/ class=md-nav__link> Logging </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7 type=checkbox id=nav-1-7> <label class=md-nav__link for=nav-1-7> Core <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Core data-md-level=2> <label class=md-nav__title for=nav-1-7> <span class="md-nav__icon md-icon"></span> Core </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../core/BroadcastManager/ class=md-nav__link> BroadcastManager </a> </li> <li class=md-nav__item> <a href=../../core/BroadcastFactory/ class=md-nav__link> BroadcastFactory </a> </li> <li class=md-nav__item> <a href=../../core/TorrentBroadcastFactory/ class=md-nav__link> TorrentBroadcastFactory </a> </li> <li class=md-nav__item> <a href=../../core/TorrentBroadcast/ class=md-nav__link> TorrentBroadcast </a> </li> <li class=md-nav__item> <a href=../../core/ContextCleaner/ class=md-nav__link> ContextCleaner </a> </li> <li class=md-nav__item> <a href=../../core/CleanerListener/ class=md-nav__link> CleanerListener </a> </li> <li class=md-nav__item> <a href=../../core/BlockFetchingListener/ class=md-nav__link> BlockFetchingListener </a> </li> <li class=md-nav__item> <a href=../../core/RetryingBlockFetcher/ class=md-nav__link> RetryingBlockFetcher </a> </li> <li class=md-nav__item> <a href=../../core/BlockFetchStarter/ class=md-nav__link> BlockFetchStarter </a> </li> <li class=md-nav__item> <a href=../../core/AppStatusListener/ class=md-nav__link> AppStatusListener </a> </li> <li class=md-nav__item> <a href=../../core/AppStatusStore/ class=md-nav__link> AppStatusStore </a> </li> <li class=md-nav__item> <a href=../../core/KVStore/ class=md-nav__link> KVStore </a> </li> <li class=md-nav__item> <a href=../../core/ElementTrackingStore/ class=md-nav__link> ElementTrackingStore </a> </li> <li class=md-nav__item> <a href=../../core/InMemoryStore/ class=md-nav__link> InMemoryStore </a> </li> <li class=md-nav__item> <a href=../../core/LevelDB/ class=md-nav__link> LevelDB </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8 type=checkbox id=nav-1-8> <label class=md-nav__link for=nav-1-8> Scheduler <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Scheduler data-md-level=2> <label class=md-nav__title for=nav-1-8> <span class="md-nav__icon md-icon"></span> Scheduler </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../scheduler/DAGScheduler/ class=md-nav__link> DAGScheduler </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-9 type=checkbox id=nav-1-9 checked> <label class=md-nav__link for=nav-1-9> Storage <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Storage data-md-level=2> <label class=md-nav__title for=nav-1-9> <span class="md-nav__icon md-icon"></span> Storage </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> BlockManager <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> BlockManager </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#sourceplaintext class=md-nav__link> [source,plaintext] </a> </li> <li class=md-nav__item> <a href=#source-scala class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_1 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala_1 class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_2 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#stop-unit class=md-nav__link> stop(): Unit </a> </li> <li class=md-nav__item> <a href=#source-scala_3 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_4 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala_2 class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_5 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#getremotevaluest-classtag-optionblockresult class=md-nav__link> getRemoteValuesT: ClassTag: Option[BlockResult] </a> </li> <li class=md-nav__item> <a href=#source-scala_6 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#gett-classtag-optionblockresult class=md-nav__link> getT: ClassTag: Option[BlockResult] </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../BlockManagerId/ class=md-nav__link> BlockManagerId </a> </li> <li class=md-nav__item> <a href=../BlockManagerInfo/ class=md-nav__link> BlockManagerInfo </a> </li> <li class=md-nav__item> <a href=../BlockManagerMaster/ class=md-nav__link> BlockManagerMaster </a> </li> <li class=md-nav__item> <a href=../BlockManagerMasterEndpoint/ class=md-nav__link> BlockManagerMasterEndpoint </a> </li> <li class=md-nav__item> <a href=../BlockManagerSlaveEndpoint/ class=md-nav__link> BlockManagerSlaveEndpoint </a> </li> <li class=md-nav__item> <a href=../BlockId/ class=md-nav__link> BlockId </a> </li> <li class=md-nav__item> <a href=../BlockDataManager/ class=md-nav__link> BlockDataManager </a> </li> <li class=md-nav__item> <a href=../DiskStore/ class=md-nav__link> DiskStore </a> </li> <li class=md-nav__item> <a href=../DiskBlockManager/ class=md-nav__link> DiskBlockManager </a> </li> <li class=md-nav__item> <a href=../MemoryStore/ class=md-nav__link> MemoryStore </a> </li> <li class=md-nav__item> <a href=../BlockEvictionHandler/ class=md-nav__link> BlockEvictionHandler </a> </li> <li class=md-nav__item> <a href=../BlockData/ class=md-nav__link> BlockData </a> </li> <li class=md-nav__item> <a href=../BlockInfoManager/ class=md-nav__link> BlockInfoManager </a> </li> <li class=md-nav__item> <a href=../BlockInfo/ class=md-nav__link> BlockInfo </a> </li> <li class=md-nav__item> <a href=../DiskBlockObjectWriter/ class=md-nav__link> DiskBlockObjectWriter </a> </li> <li class=md-nav__item> <a href=../BlockManagerSource/ class=md-nav__link> BlockManagerSource </a> </li> <li class=md-nav__item> <a href=../ShuffleMetricsSource/ class=md-nav__link> ShuffleMetricsSource </a> </li> <li class=md-nav__item> <a href=../ShuffleClient/ class=md-nav__link> ShuffleClient </a> </li> <li class=md-nav__item> <a href=../BlockTransferService/ class=md-nav__link> BlockTransferService </a> </li> <li class=md-nav__item> <a href=../NettyBlockTransferService/ class=md-nav__link> NettyBlockTransferService </a> </li> <li class=md-nav__item> <a href=../NettyBlockRpcServer/ class=md-nav__link> NettyBlockRpcServer </a> </li> <li class=md-nav__item> <a href=../ExternalShuffleClient/ class=md-nav__link> ExternalShuffleClient </a> </li> <li class=md-nav__item> <a href=../OneForOneBlockFetcher/ class=md-nav__link> OneForOneBlockFetcher </a> </li> <li class=md-nav__item> <a href=../ShuffleBlockFetcherIterator/ class=md-nav__link> ShuffleBlockFetcherIterator </a> </li> <li class=md-nav__item> <a href=../RDDInfo/ class=md-nav__link> RDDInfo </a> </li> <li class=md-nav__item> <a href=../StorageLevel/ class=md-nav__link> StorageLevel </a> </li> <li class=md-nav__item> <a href=../StorageStatus/ class=md-nav__link> StorageStatus </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Tools <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Tools data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tools/spark-shell/ class=md-nav__link> spark-shell </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> RDD <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDD data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> RDD </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/ class=md-nav__link> Resilient Distributed Dataset </a> </li> <li class=md-nav__item> <a href=../../rdd/RDD/ class=md-nav__link> RDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3 type=checkbox id=nav-3-3> <label class=md-nav__link for=nav-3-3> RDDs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDDs data-md-level=2> <label class=md-nav__title for=nav-3-3> <span class="md-nav__icon md-icon"></span> RDDs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/spark-rdd-CoGroupedRDD/ class=md-nav__link> CoGroupedRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-HadoopRDD/ class=md-nav__link> HadoopRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-MapPartitionsRDD/ class=md-nav__link> MapPartitionsRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-NewHadoopRDD/ class=md-nav__link> NewHadoopRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-OrderedRDDFunctions/ class=md-nav__link> OrderedRDDFunctions </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-ParallelCollectionRDD/ class=md-nav__link> ParallelCollectionRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/CheckpointRDD/ class=md-nav__link> CheckpointRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/ReliableCheckpointRDD/ class=md-nav__link> ReliableCheckpointRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/ShuffledRDD/ class=md-nav__link> ShuffledRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-SubtractedRDD/ class=md-nav__link> SubtractedRDD </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-4 type=checkbox id=nav-3-4> <label class=md-nav__link for=nav-3-4> Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Operators data-md-level=2> <label class=md-nav__title for=nav-3-4> <span class="md-nav__icon md-icon"></span> Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/spark-rdd-operations/ class=md-nav__link> Operators </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-transformations/ class=md-nav__link> Transformations </a> </li> <li class=md-nav__item> <a href=../../rdd/PairRDDFunctions/ class=md-nav__link> PairRDDFunctions </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-actions/ class=md-nav__link> Actions </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../rdd/Partitioner/ class=md-nav__link> Partitioner </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-lineage/ class=md-nav__link> RDD Lineage </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-caching/ class=md-nav__link> Caching and Persistence </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-partitions/ class=md-nav__link> Partitions and Partitioning </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-Partition/ class=md-nav__link> Partition </a> </li> <li class=md-nav__item> <a href=../../rdd/RDDCheckpointData/ class=md-nav__link> RDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/LocalRDDCheckpointData/ class=md-nav__link> LocalRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/ReliableRDDCheckpointData/ class=md-nav__link> ReliableRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-shuffle/ class=md-nav__link> Shuffling </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-Dependency/ class=md-nav__link> Dependencies </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-NarrowDependency/ class=md-nav__link> NarrowDependency </a> </li> <li class=md-nav__item> <a href=../../rdd/ShuffleDependency/ class=md-nav__link> ShuffleDependency </a> </li> <li class=md-nav__item> <a href=../../rdd/Aggregator/ class=md-nav__link> Aggregator </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-18 type=checkbox id=nav-3-18> <label class=md-nav__link for=nav-3-18> Partitioners <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Partitioners data-md-level=2> <label class=md-nav__title for=nav-3-18> <span class="md-nav__icon md-icon"></span> Partitioners </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/HashPartitioner/ class=md-nav__link> HashPartitioner </a> </li> <li class=md-nav__item> <a href=../../rdd/RangePartitioner/ class=md-nav__link> RangePartitioner </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Metrics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Metrics data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Metrics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/ class=md-nav__link> Spark Metrics </a> </li> <li class=md-nav__item> <a href=../../metrics/configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../metrics/MetricsSystem/ class=md-nav__link> MetricsSystem </a> </li> <li class=md-nav__item> <a href=../../metrics/MetricsConfig/ class=md-nav__link> MetricsConfig </a> </li> <li class=md-nav__item> <a href=../../metrics/Source/ class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../../metrics/Sink/ class=md-nav__link> Sink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7 type=checkbox id=nav-4-7> <label class=md-nav__link for=nav-4-7> Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sources data-md-level=2> <label class=md-nav__title for=nav-4-7> <span class="md-nav__icon md-icon"></span> Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/JvmSource/ class=md-nav__link> JvmSource </a> </li> <li class=md-nav__item> <a href=../../metrics/DAGSchedulerSource/ class=md-nav__link> DAGSchedulerSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-8 type=checkbox id=nav-4-8> <label class=md-nav__link for=nav-4-8> Sinks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sinks data-md-level=2> <label class=md-nav__title for=nav-4-8> <span class="md-nav__icon md-icon"></span> Sinks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/MetricsServlet/ class=md-nav__link> MetricsServlet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Demos <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../demo/diskblockmanager-and-block-data/ class=md-nav__link> DiskBlockManager and Block Data </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#sourceplaintext class=md-nav__link> [source,plaintext] </a> </li> <li class=md-nav__item> <a href=#source-scala class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_1 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala_1 class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_2 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#stop-unit class=md-nav__link> stop(): Unit </a> </li> <li class=md-nav__item> <a href=#source-scala_3 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_4 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#sourcescala_2 class=md-nav__link> [source,scala] </a> </li> <li class=md-nav__item> <a href=#source-scala_5 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#getremotevaluest-classtag-optionblockresult class=md-nav__link> getRemoteValuesT: ClassTag: Option[BlockResult] </a> </li> <li class=md-nav__item> <a href=#source-scala_6 class=md-nav__link> [source, scala] </a> </li> <li class=md-nav__item> <a href=#gett-classtag-optionblockresult class=md-nav__link> getT: ClassTag: Option[BlockResult] </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/japila-books/apache-spark-internals/edit/mkdocs-material/docs/storage/BlockManager.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=blockmanager>BlockManager<a class=headerlink href=#blockmanager title="Permanent link">&para;</a></h1> <p><em>BlockManager</em> manages the storage for blocks (<em>chunks of data</em>) that can be stored in &lt;<memorystore, memory>&gt; and on &lt;<diskstore, disk>&gt;.</p> <p>.BlockManager and Stores image::BlockManager.png[align="center"]</p> <p>BlockManager runs on the xref:ROOT:spark-driver.adoc[driver] and xref:executor:Executor.adoc[executors].</p> <p>BlockManager provides interface for uploading and fetching blocks both locally and remotely using various stores, i.e. &lt;<stores, memory, disk, and off-heap>&gt;.</p> <p>[[futureExecutionContext]] BlockManager uses a Scala <a href=https://www.scala-lang.org/api/current/scala/concurrent/ExecutionContextExecutorService.html[ExecutionContextExecutorService>https://www.scala-lang.org/api/current/scala/concurrent/ExecutionContextExecutorService.html[ExecutionContextExecutorService</a>] to execute <em>FIXME</em> asynchronously (on a thread pool with <em>block-manager-future</em> prefix and maximum of 128 threads).</p> <p><em>Cached blocks</em> are blocks with non-zero sum of memory and disk sizes.</p> <p>TIP: Use xref:webui:index.adoc[Web UI], esp. xref:webui:spark-webui-storage.adoc[Storage] and xref:webui:spark-webui-executors.adoc[Executors] tabs, to monitor the memory used.</p> <p>TIP: Use xref<img alt=🛠️ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f6e0.png title=:tools:>spark-submit.adoc[spark-submit]'s command-line options, i.e. xref<img alt=🛠️ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f6e0.png title=:tools:>spark-submit.adoc#driver-memory[--driver-memory] for the driver and xref<img alt=🛠️ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f6e0.png title=:tools:>spark-submit.adoc#executor-memory[--executor-memory] for executors or their equivalents as Spark properties, i.e. xref<img alt=🛠️ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f6e0.png title=:tools:>spark-submit.adoc#spark.executor.memory[spark.executor.memory] and xref<img alt=🛠️ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f6e0.png title=:tools:>spark-submit.adoc#spark_driver_memory[spark.driver.memory], to control the memory for storage memory.</p> <p>When &lt;<externalshuffleserviceenabled, external shuffle service is enabled>&gt;, BlockManager uses xref:storage:ExternalShuffleClient.adoc[ExternalShuffleClient] to read other executors' shuffle files.</p> <p>== [[creating-instance]] Creating Instance</p> <p>BlockManager takes the following to be created:</p> <ul> <li>&lt;<executorid, executor id>&gt;</li> <li>&lt;<rpcenv, rpcenv>&gt;</li> <li>&lt;<master, blockmanagermaster>&gt;</li> <li>[[serializerManager]] xref:serializer:SerializerManager.adoc[]</li> <li>[[conf]] xref:ROOT:SparkConf.adoc[]</li> <li>&lt;<memorymanager, memorymanager>&gt;</li> <li>&lt;<mapoutputtracker, mapoutputtracker>&gt;</li> <li>&lt;<shufflemanager, shufflemanager>&gt;</li> <li>&lt;<blocktransferservice, blocktransferservice>&gt;</li> <li>[[securityManager]] SecurityManager</li> <li>[[numUsableCores]] Number of CPU cores (for an xref:storage:ExternalShuffleClient.adoc[] with &lt;<externalshuffleserviceenabled, externalshuffleserviceenabled>&gt;)</li> </ul> <p>When created, BlockManager sets &lt;<externalshuffleserviceenabled, externalshuffleserviceenabled>&gt; internal flag based on xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property.</p> <p>BlockManager then creates an instance of xref:DiskBlockManager.adoc[DiskBlockManager] (requesting <code>deleteFilesOnStop</code> when an external shuffle service is not in use).</p> <p>BlockManager creates <em>block-manager-future</em> daemon cached thread pool with 128 threads maximum (as <code>futureExecutionContext</code>).</p> <p>BlockManager calculates the maximum memory to use (as <code>maxMemory</code>) by requesting the maximum xref:memory:MemoryManager.adoc#maxOnHeapStorageMemory[on-heap] and xref:memory:MemoryManager.adoc#maxOffHeapStorageMemory[off-heap] storage memory from the assigned <code>MemoryManager</code>.</p> <p>BlockManager calculates the port used by the external shuffle service (as <code>externalShuffleServicePort</code>).</p> <p>NOTE: It is computed specially in Spark on YARN.</p> <p>BlockManager creates a client to read other executors' shuffle files (as <code>shuffleClient</code>). If the external shuffle service is used an xref:storage:ExternalShuffleClient.adoc[ExternalShuffleClient] is created or the input xref:storage:BlockTransferService.adoc[BlockTransferService] is used.</p> <p>BlockManager sets the xref:ROOT:configuration-properties.adoc#spark.block.failures.beforeLocationRefresh[maximum number of failures] before this block manager refreshes the block locations from the driver (as <code>maxFailuresBeforeLocationRefresh</code>).</p> <p>BlockManager registers a xref:storage:BlockManagerSlaveEndpoint.adoc[] with the input xref:ROOT:index.adoc[RpcEnv], itself, and xref:scheduler:MapOutputTracker.adoc[MapOutputTracker] (as <code>slaveEndpoint</code>).</p> <p>BlockManager is created when SparkEnv is xref:core:SparkEnv.adoc#create-BlockManager[created] (for the driver and executors) when a Spark application starts.</p> <p>.BlockManager and SparkEnv image::BlockManager-SparkEnv.png[align="center"]</p> <p>== [[BlockEvictionHandler]] BlockEvictionHandler</p> <p>BlockManager is a xref:storage:BlockEvictionHandler.adoc[] that can &lt;<dropfrommemory, drop a block from memory>&gt; (and store it on a disk when needed).</p> <p>== [[shuffleClient]][[externalShuffleServiceEnabled]] ShuffleClient and External Shuffle Service</p> <p>BlockManager manages the lifecycle of a xref:storage:ShuffleClient.adoc[]:</p> <ul> <li> <p>Creates when &lt;<creating-instance, created>&gt;</p> </li> <li> <p>xref:storage:ShuffleClient.adoc#init[Inits] (and possibly &lt;<registerwithexternalshuffleserver, registers with an external shuffle server>&gt;) when requested to &lt;<initialize, initialize>&gt;</p> </li> <li> <p>Closes when requested to &lt;<stop, stop>&gt;</p> </li> </ul> <p>The ShuffleClient can be an xref:storage:ExternalShuffleClient.adoc[] or the given &lt;<blocktransferservice, blocktransferservice>&gt; based on xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property. When enabled, BlockManager uses the xref:storage:ExternalShuffleClient.adoc[].</p> <p>The ShuffleClient is available to other Spark services (using <code>shuffleClient</code> value) and is used when BlockStoreShuffleReader is requested to xref:shuffle:BlockStoreShuffleReader.adoc#read[read combined key-value records for a reduce task].</p> <p>When requested for &lt;<shufflemetricssource, shuffle metrics>&gt;, BlockManager simply requests xref:storage:ShuffleClient.adoc#shuffleMetrics[them] from the ShuffleClient.</p> <p>== [[rpcEnv]] BlockManager and RpcEnv</p> <p>BlockManager is given a xref:rpc:RpcEnv.adoc[] when &lt;<creating-instance, created>&gt;.</p> <p>The RpcEnv is used to set up a &lt;<slaveendpoint, blockmanagerslaveendpoint>&gt;.</p> <p>== [[blockInfoManager]] BlockInfoManager</p> <p>BlockManager creates a xref:storage:BlockInfoManager.adoc[] when &lt;<creating-instance, created>&gt;.</p> <p>BlockManager requests the BlockInfoManager to xref:storage:BlockInfoManager.adoc#clear[clear] when requested to &lt;<stop, stop>&gt;.</p> <p>BlockManager uses the BlockInfoManager to create a &lt;<memorystore, memorystore>&gt;.</p> <p>BlockManager uses the BlockInfoManager when requested for the following:</p> <ul> <li> <p>&lt;<reportallblocks, reportallblocks>&gt;</p> </li> <li> <p>&lt;<getstatus, getstatus>&gt;</p> </li> <li> <p>&lt;<getmatchingblockids, getmatchingblockids>&gt;</p> </li> <li> <p>&lt;<getlocalvalues, getlocalvalues>&gt; and &lt;<getlocalbytes, getlocalbytes>&gt;</p> </li> <li> <p>&lt;<doput, doput>&gt;</p> </li> <li> <p>&lt;<replicateblock, replicateblock>&gt;</p> </li> <li> <p>&lt;<dropfrommemory, dropfrommemory>&gt;</p> </li> <li> <p>&lt;<removerdd, removerdd>&gt;, &lt;<removebroadcast, removebroadcast>&gt;, &lt;<removeblock, removeblock>&gt;, &lt;<removeblockinternal, removeblockinternal>&gt;</p> </li> <li> <p>&lt;<downgradelock, downgradelock>&gt;, &lt;<releaselock, releaselock>&gt;, &lt;<registertask, registertask>&gt;, &lt;<releasealllocksfortask, releasealllocksfortask>&gt;</p> </li> </ul> <p>== [[master]] BlockManager and BlockManagerMaster</p> <p>BlockManager is given a xref:storage:BlockManagerMaster.adoc[] when &lt;<creating-instance, created>&gt;.</p> <p>== [[BlockDataManager]] BlockManager as BlockDataManager</p> <p>BlockManager is a xref:storage:BlockDataManager.adoc[].</p> <p>== [[mapOutputTracker]] BlockManager and MapOutputTracker</p> <p>BlockManager is given a xref:scheduler:MapOutputTracker.adoc[] when &lt;<creating-instance, created>&gt;.</p> <p>== [[executorId]] Executor ID</p> <p>BlockManager is given an Executor ID when &lt;<creating-instance, created>&gt;.</p> <p>The Executor ID is one of the following:</p> <ul> <li> <p><em>driver</em> (<code>SparkContext.DRIVER_IDENTIFIER</code>) for the driver</p> </li> <li> <p>Value of xref:executor:CoarseGrainedExecutorBackend.adoc#executor-id[--executor-id] command-line argument for xref:executor:CoarseGrainedExecutorBackend.adoc[] executors (or xref:spark-on-mesos:spark-executor-backends-MesosExecutorBackend.adoc[MesosExecutorBackend])</p> </li> </ul> <p>== [[slaveEndpoint]] BlockManagerEndpoint RPC Endpoint</p> <p>BlockManager requests the &lt;<rpcenv, rpcenv>&gt; to xref:rpc:RpcEnv.adoc#setupEndpoint[register] a xref:storage:BlockManagerSlaveEndpoint.adoc[] under the name <em>BlockManagerEndpoint[ID]</em>.</p> <p>The RPC endpoint is used when BlockManager is requested to &lt;<initialize, initialize>&gt; and &lt;<reregister, reregister>&gt; (to register the BlockManager on an executor with the &lt;<master, blockmanagermaster>&gt; on the driver).</p> <p>The endpoint is stopped (by requesting the &lt;<rpcenv, rpcenv>&gt; to xref:rpc:RpcEnv.adoc#stop[stop the reference]) when BlockManager is requested to &lt;<stop, stop>&gt;.</p> <p>== [[SparkEnv]] Accessing BlockManager Using SparkEnv</p> <p>BlockManager is available using xref:core:SparkEnv.adoc#blockManager[SparkEnv] on the driver and executors.</p> <h2 id=sourceplaintext>[source,plaintext]<a class=headerlink href=#sourceplaintext title="Permanent link">&para;</a></h2> <p>import org.apache.spark.SparkEnv val bm = SparkEnv.get.blockManager</p> <p>scala&gt; :type bm org.apache.spark.storage.BlockManager</p> <hr> <p>== [[blockTransferService]] BlockTransferService</p> <p>BlockManager is given a xref:storage:BlockTransferService.adoc[BlockTransferService] when &lt;<creating-instance, created>&gt;.</p> <p>BlockTransferService is used as the &lt;<shuffleclient, shuffleclient>&gt; when BlockManager is configured with no external shuffle service (based on xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property).</p> <p>BlockTransferService is xref:storage:BlockTransferService.adoc#init[initialized] when BlockManager &lt;<initialize, is>&gt;.</p> <p>BlockTransferService is xref:storage:BlockTransferService.adoc#close[closed] when BlockManager is requested to &lt;<stop, stop>&gt;.</p> <p>BlockTransferService is used when BlockManager is requested to &lt;<getremotebytes, fetching a block from>&gt; or &lt;<replicate, replicate a block to>&gt; remote block managers.</p> <p>== [[memoryManager]] MemoryManager</p> <p>BlockManager is given a xref:memory:MemoryManager.adoc[MemoryManager] when &lt;<creating-instance, created>&gt;.</p> <p>BlockManager uses the MemoryManager for the following:</p> <ul> <li> <p>Create the &lt;<memorystore, memorystore>&gt; (that is then assigned to xref:memory:MemoryManager.adoc#setMemoryStore[MemoryManager] as a "circular dependency")</p> </li> <li> <p>Initialize &lt;<maxonheapmemory, maxonheapmemory>&gt; and &lt;<maxoffheapmemory, maxoffheapmemory>&gt; (for reporting)</p> </li> </ul> <p>== [[shuffleManager]] ShuffleManager</p> <p>BlockManager is given a xref:shuffle:ShuffleManager.adoc[ShuffleManager] when &lt;<creating-instance, created>&gt;.</p> <p>BlockManager uses the ShuffleManager for the following:</p> <ul> <li> <p>&lt;<getblockdata, retrieving a block data>&gt; (for shuffle blocks)</p> </li> <li> <p>&lt;<getlocalbytes, retrieving a non-shuffle block data>&gt; (for shuffle blocks anyway)</p> </li> <li> <p>&lt;<registerwithexternalshuffleserver, registering an executor with a local external shuffle service>&gt; (when &lt;<initialize, initialized>&gt; on an executor with &lt;<externalshuffleserviceenabled, externalshuffleserviceenabled>&gt;)</p> </li> </ul> <p>== [[diskBlockManager]] DiskBlockManager</p> <p>BlockManager creates a xref:DiskBlockManager.adoc[DiskBlockManager] when &lt;<creating-instance, created>&gt;.</p> <p>.DiskBlockManager and BlockManager image::DiskBlockManager-BlockManager.png[align="center"]</p> <p>BlockManager uses the BlockManager for the following:</p> <ul> <li> <p>Creating a &lt;<diskstore, diskstore>&gt;</p> </li> <li> <p>&lt;<registerwithexternalshuffleserver, registering an executor with a local external shuffle service>&gt; (when &lt;<initialize, initialized>&gt; on an executor with &lt;<externalshuffleserviceenabled, externalshuffleserviceenabled>&gt;)</p> </li> </ul> <p>The BlockManager is available as <code>diskBlockManager</code> reference to other Spark systems.</p> <h2 id=source-scala>[source, scala]<a class=headerlink href=#source-scala title="Permanent link">&para;</a></h2> <p>import org.apache.spark.SparkEnv SparkEnv.get.blockManager.diskBlockManager</p> <hr> <p>== [[memoryStore]] MemoryStore</p> <p>BlockManager creates a xref:storage:MemoryStore.adoc[] when &lt;<creating-instance, created>&gt; (with the &lt;<blockinfomanager, blockinfomanager>&gt;, the &lt;<serializermanager, serializermanager>&gt;, the &lt;<memorymanager, memorymanager>&gt; and itself as a xref:storage:BlockEvictionHandler.adoc[]).</p> <p>.MemoryStore and BlockManager image::MemoryStore-BlockManager.png[align="center"]</p> <p>BlockManager requests the &lt;<memorymanager, memorymanager>&gt; to xref:memory:MemoryManager.adoc#setMemoryStore[use] the MemoryStore.</p> <p>BlockManager uses the MemoryStore for the following:</p> <ul> <li> <p>&lt;<getstatus, getstatus>&gt; and &lt;<getcurrentblockstatus, getcurrentblockstatus>&gt;</p> </li> <li> <p>&lt;<getlocalvalues, getlocalvalues>&gt;</p> </li> <li> <p>&lt;<dogetlocalbytes, dogetlocalbytes>&gt;</p> </li> <li> <p>&lt;<doputbytes, doputbytes>&gt; and &lt;<doputiterator, doputiterator>&gt;</p> </li> <li> <p>&lt;<maybecachediskbytesinmemory, maybecachediskbytesinmemory>&gt; and &lt;<maybecachediskvaluesinmemory, maybecachediskvaluesinmemory>&gt;</p> </li> <li> <p>&lt;<dropfrommemory, dropfrommemory>&gt;</p> </li> <li> <p>&lt;<removeblockinternal, removeblockinternal>&gt;</p> </li> </ul> <p>The MemoryStore is requested to xref:storage:MemoryStore.adoc#clear[clear] when BlockManager is requested to &lt;<stop, stop>&gt;.</p> <p>The MemoryStore is available as <code>memoryStore</code> private reference to other Spark services.</p> <h2 id=source-scala_1>[source, scala]<a class=headerlink href=#source-scala_1 title="Permanent link">&para;</a></h2> <p>import org.apache.spark.SparkEnv SparkEnv.get.blockManager.memoryStore</p> <hr> <p>The MemoryStore is used (via <code>SparkEnv.get.blockManager.memoryStore</code> reference) when Task is requested to xref:scheduler:Task.adoc#run[run] (that has finished and requests the MemoryStore to xref:storage:MemoryStore.adoc#releaseUnrollMemoryForThisTask[releaseUnrollMemoryForThisTask]).</p> <p>== [[diskStore]] DiskStore</p> <p>BlockManager creates a xref:DiskStore.adoc[DiskStore] (with the &lt;<diskblockmanager, diskblockmanager>&gt;) when &lt;<creating-instance, created>&gt;.</p> <p>.DiskStore and BlockManager image::DiskStore-BlockManager.png[align="center"]</p> <p>BlockManager uses the DiskStore when requested to &lt;<getstatus, getstatus>&gt;, &lt;<getcurrentblockstatus, getcurrentblockstatus>&gt;, &lt;<getlocalvalues, getlocalvalues>&gt;, &lt;<dogetlocalbytes, dogetlocalbytes>&gt;, &lt;<doputbytes, doputbytes>&gt;, &lt;<doputiterator, doputiterator>&gt;, &lt;<dropfrommemory, dropfrommemory>&gt;, &lt;<removeblockinternal, removeblockinternal>&gt;.</p> <p>== [[metrics]] Performance Metrics</p> <p>BlockManager uses link:spark-BlockManager-BlockManagerSource.adoc[BlockManagerSource] to report metrics under the name <em>BlockManager</em>.</p> <p>== [[getPeers]] getPeers Internal Method</p> <h2 id=sourcescala>[source,scala]<a class=headerlink href=#sourcescala title="Permanent link">&para;</a></h2> <p>getPeers( forceFetch: Boolean): Seq[BlockManagerId]</p> <hr> <p>getPeers...FIXME</p> <p>getPeers is used when BlockManager is requested to &lt;<replicateblock, replicateblock>&gt; and &lt;<replicate, replicate>&gt;.</p> <p>== [[releaseAllLocksForTask]] Releasing All Locks For Task</p> <h2 id=sourcescala_1>[source,scala]<a class=headerlink href=#sourcescala_1 title="Permanent link">&para;</a></h2> <p>releaseAllLocksForTask( taskAttemptId: Long): Seq[BlockId]</p> <hr> <p>releaseAllLocksForTask...FIXME</p> <p>releaseAllLocksForTask is used when TaskRunner is requested to xref:executor:TaskRunner.adoc#run[run] (at the end of a task).</p> <p>== [[stop]] Stopping BlockManager</p> <h2 id=source-scala_2>[source, scala]<a class=headerlink href=#source-scala_2 title="Permanent link">&para;</a></h2> <h2 id=stop-unit>stop(): Unit<a class=headerlink href=#stop-unit title="Permanent link">&para;</a></h2> <p>stop...FIXME</p> <p>stop is used when SparkEnv is requested to xref:core:SparkEnv.adoc#stop[stop].</p> <p>== [[getMatchingBlockIds]] Getting IDs of Existing Blocks (For a Given Filter)</p> <h2 id=source-scala_3>[source, scala]<a class=headerlink href=#source-scala_3 title="Permanent link">&para;</a></h2> <p>getMatchingBlockIds( filter: BlockId =&gt; Boolean): Seq[BlockId]</p> <hr> <p>getMatchingBlockIds...FIXME</p> <p>getMatchingBlockIds is used when BlockManagerSlaveEndpoint is requested to xref:storage:BlockManagerSlaveEndpoint.adoc#GetMatchingBlockIds[handle a GetMatchingBlockIds message].</p> <p>== [[getLocalValues]] Getting Local Block</p> <h2 id=source-scala_4>[source, scala]<a class=headerlink href=#source-scala_4 title="Permanent link">&para;</a></h2> <p>getLocalValues( blockId: BlockId): Option[BlockResult]</p> <hr> <p>getLocalValues prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Getting local block [blockId]
</code></pre></div> <p>getLocalValues xref:storage:BlockInfoManager.adoc#lockForReading[obtains a read lock for <code>blockId</code>].</p> <p>When no <code>blockId</code> block was found, you should see the following DEBUG message in the logs and getLocalValues returns "nothing" (i.e. <code>NONE</code>).</p> <div class=highlight><pre><span></span><code>Block [blockId] was not found
</code></pre></div> <p>When the <code>blockId</code> block was found, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>Level for block [blockId] is [level]
</code></pre></div> <p>If <code>blockId</code> block has memory level and xref:storage:MemoryStore.adoc#contains[is registered in <code>MemoryStore</code>], getLocalValues returns a &lt;<blockresult, blockresult>&gt; as <code>Memory</code> read method and with a <code>CompletionIterator</code> for an interator:</p> <ol> <li>xref:storage:MemoryStore.adoc#getValues[Values iterator from <code>MemoryStore</code> for <code>blockId</code>] for "deserialized" persistence levels.</li> <li>Iterator from xref:serializer:SerializerManager.adoc#dataDeserializeStream[<code>SerializerManager</code> after the data stream has been deserialized] for the <code>blockId</code> block and xref:storage:MemoryStore.adoc#getBytes[the bytes for <code>blockId</code> block] for "serialized" persistence levels.</li> </ol> <p>getLocalValues is used when:</p> <ul> <li> <p>TorrentBroadcast is requested to xref:core:TorrentBroadcast.adoc#readBroadcastBlock[readBroadcastBlock]</p> </li> <li> <p>BlockManager is requested to &lt;<get, get>&gt; and &lt;<getorelseupdate, getorelseupdate>&gt;</p> </li> </ul> <p>=== [[maybeCacheDiskValuesInMemory]] maybeCacheDiskValuesInMemory Internal Method</p> <h2 id=sourcescala_2>[source,scala]<a class=headerlink href=#sourcescala_2 title="Permanent link">&para;</a></h2> <p>maybeCacheDiskValuesInMemory<a href="blockInfo: BlockInfo,
  blockId: BlockId,
  level: StorageLevel,
  diskIterator: Iterator[T]">T</a>: Iterator[T]</p> <hr> <p>maybeCacheDiskValuesInMemory...FIXME</p> <p>maybeCacheDiskValuesInMemory is used when BlockManager is requested to &lt;<getlocalvalues, getlocalvalues>&gt;.</p> <p>== [[getRemoteValues]] <code>getRemoteValues</code> Internal Method</p> <h2 id=source-scala_5>[source, scala]<a class=headerlink href=#source-scala_5 title="Permanent link">&para;</a></h2> <h2 id=getremotevaluest-classtag-optionblockresult>getRemoteValues<a href="blockId: BlockId">T: ClassTag</a>: Option[BlockResult]<a class=headerlink href=#getremotevaluest-classtag-optionblockresult title="Permanent link">&para;</a></h2> <p><code>getRemoteValues</code>...FIXME</p> <p>== [[get]] Retrieving Block from Local or Remote Block Managers</p> <h2 id=source-scala_6>[source, scala]<a class=headerlink href=#source-scala_6 title="Permanent link">&para;</a></h2> <h2 id=gett-classtag-optionblockresult>get<a href="blockId: BlockId">T: ClassTag</a>: Option[BlockResult]<a class=headerlink href=#gett-classtag-optionblockresult title="Permanent link">&para;</a></h2> <p><code>get</code> attempts to get the <code>blockId</code> block from a local block manager first before requesting it from remote block managers.</p> <p>Internally, <code>get</code> tries to &lt;<getlocalvalues, get the block from the local blockmanager>&gt;. If the block was found, you should see the following INFO message in the logs and <code>get</code> returns the local &lt;<blockresult, blockresult>&gt;.</p> <div class=highlight><pre><span></span><code>INFO Found block [blockId] locally
</code></pre></div> <p>If however the block was not found locally, <code>get</code> tries to &lt;<getremotevalues, get the block from remote block managers>&gt;. If retrieved from a remote block manager, you should see the following INFO message in the logs and <code>get</code> returns the remote &lt;<blockresult, blockresult>&gt;.</p> <div class=highlight><pre><span></span><code>INFO Found block [blockId] remotely
</code></pre></div> <p>In the end, <code>get</code> returns "nothing" (i.e. <code>NONE</code>) when the <code>blockId</code> block was not found either in the local BlockManager or any remote BlockManager.</p> <h1 id=note>[NOTE]<a class=headerlink href=#note title="Permanent link">&para;</a></h1> <p><code>get</code> is used when:</p> <h1 id=blockmanager-is-requested-to-and>* BlockManager is requested to &lt;<getorelseupdate, getorelseupdate>&gt; and &lt;<getsingle, getsingle>&gt;<a class=headerlink href=#blockmanager-is-requested-to-and title="Permanent link">&para;</a></h1> <p>== [[getBlockData]] Retrieving Block Data</p> <h2 id=source-scala_7>[source, scala]<a class=headerlink href=#source-scala_7 title="Permanent link">&para;</a></h2> <p>getBlockData( blockId: BlockId): ManagedBuffer</p> <hr> <p>NOTE: <code>getBlockData</code> is part of the xref:storage:BlockDataManager.adoc#getBlockData[BlockDataManager] contract.</p> <p>For a xref:BlockId.adoc[] of a shuffle (a ShuffleBlockId), getBlockData requests the &lt;<shufflemanager, shufflemanager>&gt; for the xref:shuffle:ShuffleManager.adoc#shuffleBlockResolver[ShuffleBlockResolver] that is then requested for xref:shuffle:ShuffleBlockResolver.adoc#getBlockData[getBlockData].</p> <p>Otherwise, getBlockData &lt;<getlocalbytes, getlocalbytes>&gt; for the given BlockId.</p> <p>If found, getBlockData creates a new BlockManagerManagedBuffer (with the &lt;<blockinfomanager, blockinfomanager>&gt;, the input BlockId, the retrieved BlockData and the dispose flag enabled).</p> <p>If not found, getBlockData &lt;<reportblockstatus, informs the blockmanagermaster>&gt; that the block could not be found (and that the master should no longer assume the block is available on this executor) and throws a BlockNotFoundException.</p> <p>NOTE: <code>getBlockData</code> is executed for shuffle blocks or local blocks that the BlockManagerMaster knows this executor really has (unless BlockManagerMaster is outdated).</p> <p>== [[getLocalBytes]] Retrieving Non-Shuffle Local Block Data</p> <h2 id=source-scala_8>[source, scala]<a class=headerlink href=#source-scala_8 title="Permanent link">&para;</a></h2> <p>getLocalBytes( blockId: BlockId): Option[BlockData]</p> <hr> <p><code>getLocalBytes</code>...FIXME</p> <h1 id=note_1>[NOTE]<a class=headerlink href=#note_1 title="Permanent link">&para;</a></h1> <p><code>getLocalBytes</code> is used when:</p> <ul> <li>TorrentBroadcast is requested to xref:core:TorrentBroadcast.adoc#readBlocks[readBlocks]</li> </ul> <h1 id=blockmanager-is-requested-for-the-of-a-non-shuffle-block>* BlockManager is requested for the &lt;<getblockdata, block data>&gt; (of a non-shuffle block)<a class=headerlink href=#blockmanager-is-requested-for-the-of-a-non-shuffle-block title="Permanent link">&para;</a></h1> <p>== [[removeBlockInternal]] removeBlockInternal Internal Method</p> <h2 id=source-scala_9>[source, scala]<a class=headerlink href=#source-scala_9 title="Permanent link">&para;</a></h2> <p>removeBlockInternal( blockId: BlockId, tellMaster: Boolean): Unit</p> <hr> <p>removeBlockInternal...FIXME</p> <p>removeBlockInternal is used when BlockManager is requested to &lt;<doput, doput>&gt; and &lt;<removeblock, removeblock>&gt;.</p> <p>== [[stores]] Stores</p> <p>A <em>Store</em> is the place where blocks are held.</p> <p>There are the following possible stores:</p> <ul> <li>xref:storage:MemoryStore.adoc[MemoryStore] for memory storage level.</li> <li>xref:DiskStore.adoc[DiskStore] for disk storage level.</li> <li><code>ExternalBlockStore</code> for OFF_HEAP storage level.</li> </ul> <p>== [[putBlockData]] Storing Block Data Locally</p> <h2 id=source-scala_10>[source, scala]<a class=headerlink href=#source-scala_10 title="Permanent link">&para;</a></h2> <p>putBlockData( blockId: BlockId, data: ManagedBuffer, level: StorageLevel, classTag: ClassTag[_]): Boolean</p> <hr> <p><code>putBlockData</code> simply &lt;<putbytes, stores &lt;code>blockId</code> locally>&gt; (given the given storage <code>level</code>).</p> <p>NOTE: <code>putBlockData</code> is part of the xref:storage:BlockDataManager.adoc#putBlockData[BlockDataManager Contract].</p> <p>Internally, <code>putBlockData</code> wraps <code>ChunkedByteBuffer</code> around <code>data</code> buffer's NIO <code>ByteBuffer</code> and calls &lt;<putbytes, putbytes>&gt;.</p> <p>== [[putBytes]] Storing Block Bytes Locally</p> <h2 id=source-scala_11>[source, scala]<a class=headerlink href=#source-scala_11 title="Permanent link">&para;</a></h2> <p>putBytes( blockId: BlockId, bytes: ChunkedByteBuffer, level: StorageLevel, tellMaster: Boolean = true): Boolean</p> <hr> <p><code>putBytes</code> makes sure that the <code>bytes</code> are not <code>null</code> and &lt;<doputbytes, doputbytes>&gt;.</p> <h1 id=note_2>[NOTE]<a class=headerlink href=#note_2 title="Permanent link">&para;</a></h1> <p><code>putBytes</code> is used when:</p> <ul> <li> <p>BlockManager is requested to &lt;<putblockdata, puts a block data locally>&gt;</p> </li> <li> <p><code>TaskRunner</code> is requested to xref:executor:TaskRunner.adoc#run-result-sent-via-blockmanager[run] (and the result size is above xref:executor:Executor.adoc#maxDirectResultSize[maxDirectResultSize])</p> </li> </ul> <h1 id=torrentbroadcast-is-requested-to-xrefcoretorrentbroadcastadocwriteblockswriteblocks-and-xrefcoretorrentbroadcastadocreadblocksreadblocks>* <code>TorrentBroadcast</code> is requested to xref:core:TorrentBroadcast.adoc#writeBlocks[writeBlocks] and xref:core:TorrentBroadcast.adoc#readBlocks[readBlocks]<a class=headerlink href=#torrentbroadcast-is-requested-to-xrefcoretorrentbroadcastadocwriteblockswriteblocks-and-xrefcoretorrentbroadcastadocreadblocksreadblocks title="Permanent link">&para;</a></h1> <p>=== [[doPutBytes]] <code>doPutBytes</code> Internal Method</p> <h2 id=source-scala_12>[source, scala]<a class=headerlink href=#source-scala_12 title="Permanent link">&para;</a></h2> <p>doPutBytes<a href="blockId: BlockId,
  bytes: ChunkedByteBuffer,
  level: StorageLevel,
  classTag: ClassTag[T],
  tellMaster: Boolean = true,
  keepReadLock: Boolean = false">T</a>: Boolean</p> <hr> <p><code>doPutBytes</code> calls the internal helper &lt;<doput, doput>&gt; with a function that accepts a <code>BlockInfo</code> and does the uploading.</p> <p>Inside the function, if the xref:storage:StorageLevel.adoc[storage <code>level</code>]'s replication is greater than 1, it immediately starts &lt;<replicate, replication>&gt; of the <code>blockId</code> block on a separate thread (from <code>futureExecutionContext</code> thread pool). The replication uses the input <code>bytes</code> and <code>level</code> storage level.</p> <p>For a memory storage level, the function checks whether the storage <code>level</code> is deserialized or not. For a deserialized storage <code>level</code>, <code>BlockManager</code>'s xref:serializer:SerializerManager.adoc#dataDeserializeStream[<code>SerializerManager</code> deserializes <code>bytes</code> into an iterator of values] that xref:storage:MemoryStore.adoc#putIteratorAsValues[<code>MemoryStore</code> stores]. If however the storage <code>level</code> is not deserialized, the function requests xref:storage:MemoryStore.adoc#putBytes[<code>MemoryStore</code> to store the bytes]</p> <p>If the put did not succeed and the storage level is to use disk, you should see the following WARN message in the logs:</p> <div class=highlight><pre><span></span><code>WARN BlockManager: Persisting block [blockId] to disk instead.
</code></pre></div> <p>And xref:DiskStore.adoc#putBytes[<code>DiskStore</code> stores the bytes].</p> <p>NOTE: xref:DiskStore.adoc[DiskStore] is requested to store the bytes of a block with memory and disk storage level only when xref:storage:MemoryStore.adoc[MemoryStore] has failed.</p> <p>If the storage level is to use disk only, xref:DiskStore.adoc#putBytes[<code>DiskStore</code> stores the bytes].</p> <p><code>doPutBytes</code> requests &lt;<getcurrentblockstatus, current block status>&gt; and if the block was successfully stored, and the driver should know about it (<code>tellMaster</code>), the function &lt;<reportblockstatus, reports the current storage status of the block to the driver>&gt;. The xref:executor:TaskMetrics.adoc#incUpdatedBlockStatuses[current <code>TaskContext</code> metrics are updated with the updated block status] (only when executed inside a task where <code>TaskContext</code> is available).</p> <p>You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>DEBUG BlockManager: Put block [blockId] locally took [time] ms
</code></pre></div> <p>The function waits till the earlier asynchronous replication finishes for a block with replication level greater than <code>1</code>.</p> <p>The final result of <code>doPutBytes</code> is the result of storing the block successful or not (as computed earlier).</p> <p>NOTE: <code>doPutBytes</code> is used exclusively when BlockManager is requested to &lt;<putbytes, putbytes>&gt;.</p> <p>== [[doPut]] doPut Internal Method</p> <h2 id=source-scala_13>[source, scala]<a class=headerlink href=#source-scala_13 title="Permanent link">&para;</a></h2> <p>doPut<a href="blockId: BlockId,
  level: StorageLevel,
  classTag: ClassTag[_],
  tellMaster: Boolean,
  keepReadLock: Boolean">T</a>(putBody: BlockInfo =&gt; Option[T]): Option[T]</p> <hr> <p>doPut executes the input <code>putBody</code> function with a xref:storage:BlockInfo.adoc[] being a new <code>BlockInfo</code> object (with <code>level</code> storage level) that xref:storage:BlockInfoManager.adoc#lockNewBlockForWriting[<code>BlockInfoManager</code> managed to create a write lock for].</p> <p>If the block has already been created (and xref:storage:BlockInfoManager.adoc#lockNewBlockForWriting[<code>BlockInfoManager</code> did not manage to create a write lock for]), the following WARN message is printed out to the logs:</p> <h2 id=sourceplaintext_1>[source,plaintext]<a class=headerlink href=#sourceplaintext_1 title="Permanent link">&para;</a></h2> <h2 id=block-blockid-already-exists-on-this-machine-not-re-adding-it>Block [blockId] already exists on this machine; not re-adding it<a class=headerlink href=#block-blockid-already-exists-on-this-machine-not-re-adding-it title="Permanent link">&para;</a></h2> <p>doPut &lt;<releaselock, releases the read lock for the block>&gt; when <code>keepReadLock</code> flag is disabled and returns <code>None</code> immediately.</p> <p>If however the write lock has been given, doPut executes <code>putBody</code>.</p> <p>If the result of <code>putBody</code> is <code>None</code> the block is considered saved successfully.</p> <p>For successful save and <code>keepReadLock</code> enabled, xref:storage:BlockInfoManager.adoc#downgradeLock[<code>BlockInfoManager</code> is requested to downgrade an exclusive write lock for <code>blockId</code> to a shared read lock].</p> <p>For successful save and <code>keepReadLock</code> disabled, xref:storage:BlockInfoManager.adoc#unlock[<code>BlockInfoManager</code> is requested to release lock on <code>blockId</code>].</p> <p>For unsuccessful save, &lt;<removeblockinternal, the block is removed from memory and disk stores>&gt; and the following WARN message is printed out to the logs:</p> <h2 id=sourceplaintext_2>[source,plaintext]<a class=headerlink href=#sourceplaintext_2 title="Permanent link">&para;</a></h2> <h2 id=putting-block-blockid-failed>Putting block [blockId] failed<a class=headerlink href=#putting-block-blockid-failed title="Permanent link">&para;</a></h2> <p>In the end, doPut prints out the following DEBUG message to the logs:</p> <h2 id=sourceplaintext_3>[source,plaintext]<a class=headerlink href=#sourceplaintext_3 title="Permanent link">&para;</a></h2> <h2 id=putting-block-blockid-withorwithout-replication-took-usedtime-ms>Putting block [blockId] [withOrWithout] replication took [usedTime] ms<a class=headerlink href=#putting-block-blockid-withorwithout-replication-took-usedtime-ms title="Permanent link">&para;</a></h2> <p>doPut is used when BlockManager is requested to &lt;<doputbytes, doputbytes>&gt; and &lt;<doputiterator, doputiterator>&gt;.</p> <p>== [[removeBlock]] Removing Block From Memory and Disk</p> <h2 id=source-scala_14>[source, scala]<a class=headerlink href=#source-scala_14 title="Permanent link">&para;</a></h2> <p>removeBlock( blockId: BlockId, tellMaster: Boolean = true): Unit</p> <hr> <p>removeBlock removes the <code>blockId</code> block from the xref:storage:MemoryStore.adoc[MemoryStore] and xref:DiskStore.adoc[DiskStore].</p> <p>When executed, it prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Removing block [blockId]
</code></pre></div> <p>It requests xref:storage:BlockInfoManager.adoc[] for lock for writing for the <code>blockId</code> block. If it receives none, it prints out the following WARN message to the logs and quits.</p> <div class=highlight><pre><span></span><code>Asked to remove block [blockId], which does not exist
</code></pre></div> <p>Otherwise, with a write lock for the block, the block is removed from xref:storage:MemoryStore.adoc[MemoryStore] and xref:DiskStore.adoc[DiskStore] (see xref:storage:MemoryStore.adoc#remove[Removing Block in <code>MemoryStore</code>] and xref:DiskStore.adoc#remove[Removing Block in <code>DiskStore</code>]).</p> <p>If both removals fail, it prints out the following WARN message:</p> <div class=highlight><pre><span></span><code>Block [blockId] could not be removed as it was not found in either the disk, memory, or external block store
</code></pre></div> <p>The block is removed from xref:storage:BlockInfoManager.adoc[].</p> <p>removeBlock then &lt;<getcurrentblockstatus, calculates the current block status>&gt; that is used to &lt;<reportblockstatus, report the block status to the driver>&gt; (if the input <code>tellMaster</code> and the info's <code>tellMaster</code> are both enabled, i.e. <code>true</code>) and the xref:executor:TaskMetrics.adoc#incUpdatedBlockStatuses[current TaskContext metrics are updated with the change].</p> <p>removeBlock is used when:</p> <ul> <li> <p>BlockManager is requested to &lt;<handlelocalreadfailure, handlelocalreadfailure>&gt;, &lt;<removerdd, remove an rdd>&gt; and &lt;<removebroadcast, broadcast>&gt;</p> </li> <li> <p>BlockManagerSlaveEndpoint is requested to handle a xref:storage:BlockManagerSlaveEndpoint.adoc#RemoveBlock[RemoveBlock] message</p> </li> </ul> <p>== [[removeRdd]] Removing RDD Blocks</p> <h2 id=source-scala_15>[source, scala]<a class=headerlink href=#source-scala_15 title="Permanent link">&para;</a></h2> <h2 id=removerddrddid-int-int>removeRdd(rddId: Int): Int<a class=headerlink href=#removerddrddid-int-int title="Permanent link">&para;</a></h2> <p><code>removeRdd</code> removes all the blocks that belong to the <code>rddId</code> RDD.</p> <p>It prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>INFO Removing RDD [rddId]
</code></pre></div> <p>It then requests RDD blocks from xref:storage:BlockInfoManager.adoc[] and &lt;<removeblock, removes them (from memory and disk)>&gt; (without informing the driver).</p> <p>The number of blocks removed is the final result.</p> <p>NOTE: It is used by xref:storage:BlockManagerSlaveEndpoint.adoc#RemoveRdd[<code>BlockManagerSlaveEndpoint</code> while handling <code>RemoveRdd</code> messages].</p> <p>== [[removeBroadcast]] Removing All Blocks of Broadcast Variable</p> <h2 id=source-scala_16>[source, scala]<a class=headerlink href=#source-scala_16 title="Permanent link">&para;</a></h2> <h2 id=removebroadcastbroadcastid-long-tellmaster-boolean-int>removeBroadcast(broadcastId: Long, tellMaster: Boolean): Int<a class=headerlink href=#removebroadcastbroadcastid-long-tellmaster-boolean-int title="Permanent link">&para;</a></h2> <p><code>removeBroadcast</code> removes all the blocks of the input <code>broadcastId</code> broadcast.</p> <p>Internally, it starts by printing out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Removing broadcast [broadcastId]
</code></pre></div> <p>It then requests all the xref:storage:BlockId.adoc#BroadcastBlockId[BroadcastBlockId] objects that belong to the <code>broadcastId</code> broadcast from xref:storage:BlockInfoManager.adoc[] and &lt;<removeblock, removes them (from memory and disk)>&gt;.</p> <p>The number of blocks removed is the final result.</p> <p>NOTE: It is used by xref:storage:BlockManagerSlaveEndpoint.adoc#RemoveBroadcast[<code>BlockManagerSlaveEndpoint</code> while handling <code>RemoveBroadcast</code> messages].</p> <p>== [[shuffleServerId]] BlockManagerId of Shuffle Server</p> <p>BlockManager uses xref:storage:BlockManagerId.adoc[] for the location (address) of the server that serves shuffle files of this executor.</p> <p>The BlockManagerId is either the BlockManagerId of the external shuffle service (when &lt;<externalshuffleserviceenabled, enabled>&gt;) or the &lt;<blockmanagerid, blockmanagerid>&gt;.</p> <p>The BlockManagerId of the Shuffle Server is used for the location of a xref:scheduler:MapStatus.adoc[shuffle map output] when:</p> <ul> <li> <p>BypassMergeSortShuffleWriter is requested to xref:shuffle:BypassMergeSortShuffleWriter.adoc#write[write partition records to a shuffle file]</p> </li> <li> <p>UnsafeShuffleWriter is requested to xref:shuffle:UnsafeShuffleWriter.adoc#closeAndWriteOutput[close and write output]</p> </li> </ul> <p>== [[getStatus]] getStatus Method</p> <h2 id=sourcescala_3>[source,scala]<a class=headerlink href=#sourcescala_3 title="Permanent link">&para;</a></h2> <p>getStatus( blockId: BlockId): Option[BlockStatus]</p> <hr> <p>getStatus...FIXME</p> <p>getStatus is used when BlockManagerSlaveEndpoint is requested to handle xref:storage:BlockManagerSlaveEndpoint.adoc#GetBlockStatus[GetBlockStatus] message.</p> <p>== [[initialize]] Initializing BlockManager</p> <h2 id=source-scala_17>[source, scala]<a class=headerlink href=#source-scala_17 title="Permanent link">&para;</a></h2> <p>initialize( appId: String): Unit</p> <hr> <p>initialize initializes a BlockManager on the driver and executors (see xref:ROOT:SparkContext.adoc#creating-instance[Creating SparkContext Instance] and xref:executor:Executor.adoc#creating-instance[Creating Executor Instance], respectively).</p> <p>NOTE: The method must be called before a BlockManager can be considered fully operable.</p> <p>initialize does the following in order:</p> <ol> <li>Initializes xref:storage:BlockTransferService.adoc#init[BlockTransferService]</li> <li>Initializes the internal shuffle client, be it xref:storage:ExternalShuffleClient.adoc[ExternalShuffleClient] or xref:storage:BlockTransferService.adoc[BlockTransferService].</li> <li>xref:BlockManagerMaster.adoc#registerBlockManager[Registers itself with the driver's <code>BlockManagerMaster</code>] (using the <code>id</code>, <code>maxMemory</code> and its <code>slaveEndpoint</code>). + The <code>BlockManagerMaster</code> reference is passed in when the &lt;<creating-instance, blockmanager is created>&gt; on the driver and executors.</li> <li>Sets &lt;<shuffleserverid, shuffleserverid>&gt; to an instance of xref:storage:BlockManagerId.adoc[] given an executor id, host name and port for xref:storage:BlockTransferService.adoc[BlockTransferService].</li> <li>It creates the address of the server that serves this executor's shuffle files (using &lt;<shuffleserverid, shuffleserverid>&gt;)</li> </ol> <p>CAUTION: FIXME Review the initialize procedure again</p> <p>CAUTION: FIXME Describe <code>shuffleServerId</code>. Where is it used?</p> <p>If the &lt;<externalshuffleserviceenabled, external shuffle service is used>&gt;, initialize prints out the following INFO message to the logs:</p> <h2 id=sourceplaintext_4>[source,plaintext]<a class=headerlink href=#sourceplaintext_4 title="Permanent link">&para;</a></h2> <h2 id=external-shuffle-service-port-externalshuffleserviceport>external shuffle service port = [externalShuffleServicePort]<a class=headerlink href=#external-shuffle-service-port-externalshuffleserviceport title="Permanent link">&para;</a></h2> <p>It xref:BlockManagerMaster.adoc#registerBlockManager[registers itself to the driver's BlockManagerMaster] passing the xref:storage:BlockManagerId.adoc[], the maximum memory (as <code>maxMemory</code>), and the xref:storage:BlockManagerSlaveEndpoint.adoc[].</p> <p>Ultimately, if the initialization happens on an executor and the &lt;<externalshuffleserviceenabled, external shuffle service is used>&gt;, it &lt;<registerwithexternalshuffleserver, registers to the shuffle service>&gt;.</p> <p>initialize is used when the link:spark-SparkContext-creating-instance-internals.adoc#BlockManager-initialization[driver is launched (and <code>SparkContext</code> is created)] and when an xref:executor:Executor.adoc#creating-instance[<code>Executor</code> is created] (for xref:executor:CoarseGrainedExecutorBackend.adoc#RegisteredExecutor[CoarseGrainedExecutorBackend] and xref:spark-on-mesos:spark-executor-backends-MesosExecutorBackend.adoc[MesosExecutorBackend]).</p> <p>== [[registerWithExternalShuffleServer]] Registering Executor's BlockManager with External Shuffle Server</p> <h2 id=source-scala_18>[source, scala]<a class=headerlink href=#source-scala_18 title="Permanent link">&para;</a></h2> <h2 id=registerwithexternalshuffleserver-unit>registerWithExternalShuffleServer(): Unit<a class=headerlink href=#registerwithexternalshuffleserver-unit title="Permanent link">&para;</a></h2> <p>registerWithExternalShuffleServer is an internal helper method to register the BlockManager for an executor with an xref:deploy:ExternalShuffleService.adoc[external shuffle server].</p> <p>NOTE: It is executed when a &lt;<initialize, blockmanager is initialized on an executor and an external shuffle service is used>&gt;.</p> <p>When executed, you should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Registering executor with local external shuffle service.
</code></pre></div> <p>It uses &lt;<shuffleclient, shuffleclient>&gt; to xref:storage:ExternalShuffleClient.adoc#registerWithShuffleServer[register the block manager] using &lt;<shuffleserverid, shuffleserverid>&gt; (i.e. the host, the port and the executorId) and a <code>ExecutorShuffleInfo</code>.</p> <p>NOTE: The <code>ExecutorShuffleInfo</code> uses <code>localDirs</code> and <code>subDirsPerLocalDir</code> from xref:DiskBlockManager.adoc[DiskBlockManager] and the class name of the constructor xref:shuffle:ShuffleManager.adoc[ShuffleManager].</p> <p>It tries to register at most 3 times with 5-second sleeps in-between.</p> <p>NOTE: The maximum number of attempts and the sleep time in-between are hard-coded, i.e. they are not configured.</p> <p>Any issues while connecting to the external shuffle service are reported as ERROR messages in the logs:</p> <div class=highlight><pre><span></span><code>Failed to connect to external shuffle server, will retry [#attempts] more times after waiting 5 seconds...
</code></pre></div> <p>registerWithExternalShuffleServer is used when BlockManager is requested to &lt;<initialize, initialize>&gt; (when executed on an executor with &lt;<externalshuffleserviceenabled, externalshuffleserviceenabled>&gt;).</p> <p>== [[reregister]] Re-registering BlockManager with Driver and Reporting Blocks</p> <h2 id=source-scala_19>[source, scala]<a class=headerlink href=#source-scala_19 title="Permanent link">&para;</a></h2> <h2 id=reregister-unit>reregister(): Unit<a class=headerlink href=#reregister-unit title="Permanent link">&para;</a></h2> <p>When executed, reregister prints the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>BlockManager [blockManagerId] re-registering with master
</code></pre></div> <p>reregister then xref:BlockManagerMaster.adoc#registerBlockManager[registers itself to the driver's <code>BlockManagerMaster</code>] (just as it was when &lt;<initialize, blockmanager was initializing>&gt;). It passes the xref:storage:BlockManagerId.adoc[], the maximum memory (as <code>maxMemory</code>), and the xref:storage:BlockManagerSlaveEndpoint.adoc[].</p> <p>reregister will then report all the local blocks to the xref:BlockManagerMaster.adoc[BlockManagerMaster].</p> <p>You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Reporting [blockInfoManager.size] blocks to the master.
</code></pre></div> <p>For each block metadata (in xref:storage:BlockInfoManager.adoc[]) it &lt;<getcurrentblockstatus, gets block current status>&gt; and &lt;<trytoreportblockstatus, tries to send it to the blockmanagermaster>&gt;.</p> <p>If there is an issue communicating to the xref:BlockManagerMaster.adoc[BlockManagerMaster], you should see the following ERROR message in the logs:</p> <div class=highlight><pre><span></span><code>Failed to report [blockId] to master; giving up.
</code></pre></div> <p>After the ERROR message, reregister stops reporting.</p> <p>reregister is used when a xref:executor:Executor.adoc#heartbeats-and-active-task-metrics[<code>Executor</code> was informed to re-register while sending heartbeats].</p> <p>== [[getCurrentBlockStatus]] Calculate Current Block Status</p> <h2 id=source-scala_20>[source, scala]<a class=headerlink href=#source-scala_20 title="Permanent link">&para;</a></h2> <p>getCurrentBlockStatus( blockId: BlockId, info: BlockInfo): BlockStatus</p> <hr> <p>getCurrentBlockStatus gives the current <code>BlockStatus</code> of the <code>BlockId</code> block (with the block's current xref:storage:StorageLevel.adoc[StorageLevel], memory and disk sizes). It uses xref:storage:MemoryStore.adoc[MemoryStore] and xref:DiskStore.adoc[DiskStore] for size and other information.</p> <p>NOTE: Most of the information to build <code>BlockStatus</code> is already in <code>BlockInfo</code> except that it may not necessarily reflect the current state per xref:storage:MemoryStore.adoc[MemoryStore] and xref:DiskStore.adoc[DiskStore].</p> <p>Internally, it uses the input xref:storage:BlockInfo.adoc[] to know about the block's storage level. If the storage level is not set (i.e. <code>null</code>), the returned <code>BlockStatus</code> assumes the xref:storage:StorageLevel.adoc[default <code>NONE</code> storage level] and the memory and disk sizes being <code>0</code>.</p> <p>If however the storage level is set, getCurrentBlockStatus uses xref:storage:MemoryStore.adoc[MemoryStore] and xref:DiskStore.adoc[DiskStore] to check whether the block is stored in the storages or not and request for their sizes in the storages respectively (using their <code>getSize</code> or assume <code>0</code>).</p> <p>NOTE: It is acceptable that the <code>BlockInfo</code> says to use memory or disk yet the block is not in the storages (yet or anymore). The method will give current status.</p> <p>getCurrentBlockStatus is used when &lt;<reregister, executor&#x27;s blockmanager is requested to report the current status of the local blocks to the master>&gt;, &lt;<doputbytes, saving a block to a storage>&gt; or &lt;<dropfrommemory, removing a block from memory only>&gt; or &lt;<removeblock, both, i.e. from memory and disk>&gt;.</p> <p>== [[reportAllBlocks]] reportAllBlocks Internal Method</p> <h2 id=source-scala_21>[source, scala]<a class=headerlink href=#source-scala_21 title="Permanent link">&para;</a></h2> <h2 id=reportallblocks-unit>reportAllBlocks(): Unit<a class=headerlink href=#reportallblocks-unit title="Permanent link">&para;</a></h2> <p>reportAllBlocks...FIXME</p> <p>reportAllBlocks is used when BlockManager is requested to &lt;<reregister, re-register all blocks to the driver>&gt;.</p> <p>== [[reportBlockStatus]] Reporting Current Storage Status of Block to Driver</p> <h2 id=source-scala_22>[source, scala]<a class=headerlink href=#source-scala_22 title="Permanent link">&para;</a></h2> <p>reportBlockStatus( blockId: BlockId, info: BlockInfo, status: BlockStatus, droppedMemorySize: Long = 0L): Unit</p> <hr> <p>reportBlockStatus is an internal method for &lt;<trytoreportblockstatus, reporting a block status to the driver>&gt; and if told to re-register it prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Got told to re-register updating block [blockId]
</code></pre></div> <p>It does asynchronous reregistration (using <code>asyncReregister</code>).</p> <p>In either case, it prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>Told master about block [blockId]
</code></pre></div> <p>reportBlockStatus is used when BlockManager is requested to &lt;<getblockdata, getblockdata>&gt;, &lt;<doputbytes, doputbytes>&gt;, &lt;<doputiterator, doputiterator>&gt;, &lt;<dropfrommemory, dropfrommemory>&gt; and &lt;<removeblockinternal, removeblockinternal>&gt;.</p> <p>== [[tryToReportBlockStatus]] Reporting Block Status Update to Driver</p> <h2 id=source-scala_23>[source, scala]<a class=headerlink href=#source-scala_23 title="Permanent link">&para;</a></h2> <p>def tryToReportBlockStatus( blockId: BlockId, info: BlockInfo, status: BlockStatus, droppedMemorySize: Long = 0L): Boolean</p> <hr> <p>tryToReportBlockStatus xref:BlockManagerMaster.adoc#updateBlockInfo[reports block status update] to &lt;<master, blockmanagermaster>&gt; and returns its response.</p> <p>tryToReportBlockStatus is used when BlockManager is requested to &lt;<reportallblocks, reportallblocks>&gt; or &lt;<reportblockstatus, reportblockstatus>&gt;.</p> <p>== [[execution-context]] Execution Context</p> <p><em>block-manager-future</em> is the execution context for...FIXME</p> <p>== [[ByteBuffer]] ByteBuffer</p> <p>The underlying abstraction for blocks in Spark is a <code>ByteBuffer</code> that limits the size of a block to 2GB (<code>Integer.MAX_VALUE</code> - see <a href=http://stackoverflow.com/q/8076472/1305344[Why>http://stackoverflow.com/q/8076472/1305344[Why</a> does FileChannel.map take up to Integer.MAX_VALUE of data?] and <a href=https://issues.apache.org/jira/browse/SPARK-1476[SPARK-1476>https://issues.apache.org/jira/browse/SPARK-1476[SPARK-1476</a> 2GB limit in spark for blocks]). This has implication not just for managed blocks in use, but also for shuffle blocks (memory mapped blocks are limited to 2GB, even though the API allows for <code>long</code>), ser-deser via byte array-backed output streams.</p> <p>== [[BlockResult]] BlockResult</p> <p><code>BlockResult</code> is a description of a fetched block with the <code>readMethod</code> and <code>bytes</code>.</p> <p>== [[registerTask]] Registering Task</p> <h2 id=source-scala_24>[source, scala]<a class=headerlink href=#source-scala_24 title="Permanent link">&para;</a></h2> <p>registerTask( taskAttemptId: Long): Unit</p> <hr> <p>registerTask requests the &lt;<blockinfomanager, blockinfomanager>&gt; to xref:storage:BlockInfoManager.adoc#registerTask[register a given task].</p> <p>registerTask is used when Task is requested to xref:scheduler:Task.adoc#run[run] (at the start of a task).</p> <p>== [[getDiskWriter]] Creating DiskBlockObjectWriter</p> <h2 id=source-scala_25>[source, scala]<a class=headerlink href=#source-scala_25 title="Permanent link">&para;</a></h2> <p>getDiskWriter( blockId: BlockId, file: File, serializerInstance: SerializerInstance, bufferSize: Int, writeMetrics: ShuffleWriteMetrics): DiskBlockObjectWriter</p> <hr> <p>getDiskWriter creates a xref:storage:DiskBlockObjectWriter.adoc[DiskBlockObjectWriter] (with xref:ROOT:configuration-properties.adoc#spark.shuffle.sync[spark.shuffle.sync] configuration property for syncWrites argument).</p> <p>getDiskWriter uses the &lt;<serializermanager, serializermanager>&gt; of the BlockManager.</p> <p>getDiskWriter is used when:</p> <ul> <li> <p>BypassMergeSortShuffleWriter is requested to xref:shuffle:BypassMergeSortShuffleWriter.adoc#write[write records (of a partition)]</p> </li> <li> <p>ShuffleExternalSorter is requested to xref:shuffle:ShuffleExternalSorter.adoc#writeSortedFile[writeSortedFile]</p> </li> <li> <p>ExternalAppendOnlyMap is requested to xref:shuffle:ExternalAppendOnlyMap.adoc#spillMemoryIteratorToDisk[spillMemoryIteratorToDisk]</p> </li> <li> <p>ExternalSorter is requested to xref:shuffle:ExternalSorter.adoc#spillMemoryIteratorToDisk[spillMemoryIteratorToDisk] and xref:shuffle:ExternalSorter.adoc#writePartitionedFile[writePartitionedFile]</p> </li> <li> <p>xref:memory:UnsafeSorterSpillWriter.adoc[UnsafeSorterSpillWriter] is created</p> </li> </ul> <p>== [[addUpdatedBlockStatusToTaskMetrics]] Recording Updated BlockStatus In Current Task's TaskMetrics</p> <h2 id=source-scala_26>[source, scala]<a class=headerlink href=#source-scala_26 title="Permanent link">&para;</a></h2> <p>addUpdatedBlockStatusToTaskMetrics( blockId: BlockId, status: BlockStatus): Unit</p> <hr> <p>addUpdatedBlockStatusToTaskMetrics link:spark-TaskContext.adoc#get[takes an active <code>TaskContext</code>] (if available) and xref:executor:TaskMetrics.adoc#incUpdatedBlockStatuses[records updated <code>BlockStatus</code> for <code>Block</code>] (in the link:spark-TaskContext.adoc#taskMetrics[task's <code>TaskMetrics</code>]).</p> <p>addUpdatedBlockStatusToTaskMetrics is used when BlockManager &lt;<doputbytes, doputbytes>&gt; (for a block that was successfully stored), &lt;<doput, doput>&gt;, &lt;<doputiterator, doputiterator>&gt;, &lt;<dropfrommemory, removes blocks from memory>&gt; (possibly spilling it to disk) and &lt;<removeblock, removes block from memory and disk>&gt;.</p> <p>== [[shuffleMetricsSource]] Requesting Shuffle-Related Spark Metrics Source</p> <h2 id=source-scala_27>[source, scala]<a class=headerlink href=#source-scala_27 title="Permanent link">&para;</a></h2> <h2 id=shufflemetricssource-source>shuffleMetricsSource: Source<a class=headerlink href=#shufflemetricssource-source title="Permanent link">&para;</a></h2> <p>shuffleMetricsSource requests the &lt;<shuffleclient, shuffleclient>&gt; for the xref:storage:ShuffleClient.adoc#shuffleMetrics[shuffle metrics] and creates a xref:storage:ShuffleMetricsSource.adoc[] with the xref:storage:ShuffleMetricsSource.adoc#sourceName[source name] based on xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property:</p> <ul> <li> <p><em>ExternalShuffle</em> when xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property is on (<code>true</code>)</p> </li> <li> <p><em>NettyBlockTransfer</em> when xref:ROOT:configuration-properties.adoc#spark.shuffle.service.enabled[spark.shuffle.service.enabled] configuration property is off (<code>false</code>)</p> </li> </ul> <p>shuffleMetricsSource is used when Executor is xref:executor:Executor.adoc#creating-instance[created] (for non-local / cluster modes).</p> <p>== [[replicate]] Replicating Block To Peers</p> <h2 id=source-scala_28>[source, scala]<a class=headerlink href=#source-scala_28 title="Permanent link">&para;</a></h2> <p>replicate( blockId: BlockId, data: BlockData, level: StorageLevel, classTag: ClassTag[_], existingReplicas: Set[BlockManagerId] = Set.empty): Unit</p> <hr> <p>replicate...FIXME</p> <p>replicate is used when BlockManager is requested to &lt;<doputbytes, doputbytes>&gt;, &lt;<doputiterator, doputiterator>&gt; and &lt;<replicateblock, replicateblock>&gt;.</p> <p>== [[replicateBlock]] replicateBlock Method</p> <h2 id=source-scala_29>[source, scala]<a class=headerlink href=#source-scala_29 title="Permanent link">&para;</a></h2> <p>replicateBlock( blockId: BlockId, existingReplicas: Set[BlockManagerId], maxReplicas: Int): Unit</p> <hr> <p>replicateBlock...FIXME</p> <p>replicateBlock is used when BlockManagerSlaveEndpoint is requested to xref:storage:BlockManagerSlaveEndpoint.adoc#ReplicateBlock[handle a ReplicateBlock message].</p> <p>== [[putIterator]] <code>putIterator</code> Method</p> <h2 id=source-scala_30>[source, scala]<a class=headerlink href=#source-scala_30 title="Permanent link">&para;</a></h2> <p>putIterator<a href="blockId: BlockId,
  values: Iterator[T],
  level: StorageLevel,
  tellMaster: Boolean = true">T: ClassTag</a>: Boolean</p> <hr> <p><code>putIterator</code>...FIXME</p> <h1 id=note_3>[NOTE]<a class=headerlink href=#note_3 title="Permanent link">&para;</a></h1> <p><code>putIterator</code> is used when:</p> <ul> <li>BlockManager is requested to &lt;<putsingle, putsingle>&gt;</li> </ul> <h1 id=spark-streamings-blockmanagerbasedblockhandler-is-requested-to-storeblock>* Spark Streaming's <code>BlockManagerBasedBlockHandler</code> is requested to <code>storeBlock</code><a class=headerlink href=#spark-streamings-blockmanagerbasedblockhandler-is-requested-to-storeblock title="Permanent link">&para;</a></h1> <p>== [[putSingle]] putSingle Method</p> <h2 id=source-scala_31>[source, scala]<a class=headerlink href=#source-scala_31 title="Permanent link">&para;</a></h2> <p>putSingle<a href="blockId: BlockId,
  value: T,
  level: StorageLevel,
  tellMaster: Boolean = true">T: ClassTag</a>: Boolean</p> <hr> <p>putSingle...FIXME</p> <p>putSingle is used when TorrentBroadcast is requested to xref:core:TorrentBroadcast.adoc#writeBlocks[write the blocks] and xref:core:TorrentBroadcast.adoc#readBroadcastBlock[readBroadcastBlock].</p> <p>== [[getRemoteBytes]] Fetching Block From Remote Nodes</p> <h2 id=source-scala_32>[source, scala]<a class=headerlink href=#source-scala_32 title="Permanent link">&para;</a></h2> <h2 id=getremotebytesblockid-blockid-optionchunkedbytebuffer>getRemoteBytes(blockId: BlockId): Option[ChunkedByteBuffer]<a class=headerlink href=#getremotebytesblockid-blockid-optionchunkedbytebuffer title="Permanent link">&para;</a></h2> <p><code>getRemoteBytes</code>...FIXME</p> <h1 id=note_4>[NOTE]<a class=headerlink href=#note_4 title="Permanent link">&para;</a></h1> <p><code>getRemoteBytes</code> is used when:</p> <ul> <li> <p>BlockManager is requested to &lt;<getremotevalues, getremotevalues>&gt;</p> </li> <li> <p><code>TorrentBroadcast</code> is requested to xref:core:TorrentBroadcast.adoc#readBlocks[readBlocks]</p> </li> </ul> <h1 id=taskresultgetter-is-requested-to-xrefschedulertaskresultgetteradocenqueuesuccessfultaskenqueuing-a-successful-indirecttaskresult>* <code>TaskResultGetter</code> is requested to xref:scheduler:TaskResultGetter.adoc#enqueueSuccessfulTask[enqueuing a successful IndirectTaskResult]<a class=headerlink href=#taskresultgetter-is-requested-to-xrefschedulertaskresultgetteradocenqueuesuccessfultaskenqueuing-a-successful-indirecttaskresult title="Permanent link">&para;</a></h1> <p>== [[getRemoteValues]] <code>getRemoteValues</code> Internal Method</p> <h2 id=source-scala_33>[source, scala]<a class=headerlink href=#source-scala_33 title="Permanent link">&para;</a></h2> <h2 id=getremotevaluest-classtag-optionblockresult_1>getRemoteValues<a href="blockId: BlockId">T: ClassTag</a>: Option[BlockResult]<a class=headerlink href=#getremotevaluest-classtag-optionblockresult_1 title="Permanent link">&para;</a></h2> <p><code>getRemoteValues</code>...FIXME</p> <p>NOTE: <code>getRemoteValues</code> is used exclusively when BlockManager is requested to &lt;<get, get a block by blockid>&gt;.</p> <p>== [[getSingle]] <code>getSingle</code> Method</p> <h2 id=source-scala_34>[source, scala]<a class=headerlink href=#source-scala_34 title="Permanent link">&para;</a></h2> <h2 id=getsinglet-classtag-optiont>getSingle<a href="blockId: BlockId">T: ClassTag</a>: Option[T]<a class=headerlink href=#getsinglet-classtag-optiont title="Permanent link">&para;</a></h2> <p><code>getSingle</code>...FIXME</p> <p>NOTE: <code>getSingle</code> is used exclusively in Spark tests.</p> <p>== [[getOrElseUpdate]] Getting Block From Block Managers Or Computing and Storing It Otherwise</p> <h2 id=source-scala_35>[source, scala]<a class=headerlink href=#source-scala_35 title="Permanent link">&para;</a></h2> <p>getOrElseUpdate<a href="blockId: BlockId,
  level: StorageLevel,
  classTag: ClassTag[T],
  makeIterator: () => Iterator[T]">T</a>: Either[BlockResult, Iterator[T]]</p> <hr> <h1 id=note_5>[NOTE]<a class=headerlink href=#note_5 title="Permanent link">&para;</a></h1> <p><em>I think</em> it is fair to say that <code>getOrElseUpdate</code> is like link:++<a href="https://www.scala-lang.org/api/current/scala/collection/mutable/Map.html#getOrElseUpdate(key:K,op:=%3EV):V++[getOrElseUpdate">https://www.scala-lang.org/api/current/scala/collection/mutable/Map.html#getOrElseUpdate(key:K,op:=%3EV):V++[getOrElseUpdate</a>] of <a href=https://www.scala-lang.org/api/current/scala/collection/mutable/Map.html[scala.collection.mutable.Map>https://www.scala-lang.org/api/current/scala/collection/mutable/Map.html[scala.collection.mutable.Map</a>] in Scala.</p> <h2 id=source-scala_36>[source, scala]<a class=headerlink href=#source-scala_36 title="Permanent link">&para;</a></h2> <h2 id=getorelseupdatekey-k-op-v-v>getOrElseUpdate(key: K, op: ⇒ V): V<a class=headerlink href=#getorelseupdatekey-k-op-v-v title="Permanent link">&para;</a></h2> <p>Quoting the official scaladoc:</p> <p>If given key <code>K</code> is already in this map, <code>getOrElseUpdate</code> returns the associated value <code>V</code>.</p> <p>Otherwise, <code>getOrElseUpdate</code> computes a value <code>V</code> from given expression <code>op</code>, stores with the key <code>K</code> in the map and returns that value.</p> <h1 id=since-blockmanager-is-a-key-value-store-of-blocks-of-data-identified-by-a-block-id-that-works-just-fine>Since BlockManager is a key-value store of blocks of data identified by a block ID that works just fine.<a class=headerlink href=#since-blockmanager-is-a-key-value-store-of-blocks-of-data-identified-by-a-block-id-that-works-just-fine title="Permanent link">&para;</a></h1> <p><code>getOrElseUpdate</code> first attempts to &lt;<get, get the block>&gt; by the <code>BlockId</code> (from the local block manager first and, if unavailable, requesting remote peers).</p> <h1 id=tip>[TIP]<a class=headerlink href=#tip title="Permanent link">&para;</a></h1> <p>Enable <code>INFO</code> logging level for <code>org.apache.spark.storage.BlockManager</code> logger to see what happens when BlockManager tries to &lt;<get, get a block>&gt;.</p> <h1 id=see-in-this-document>See &lt;<logging, logging>&gt; in this document.<a class=headerlink href=#see-in-this-document title="Permanent link">&para;</a></h1> <p><code>getOrElseUpdate</code> gives the <code>BlockResult</code> of the block if found.</p> <p>If however the block was not found (in any block manager in a Spark cluster), <code>getOrElseUpdate</code> &lt;<doputiterator, doputiterator>&gt; (for the input <code>BlockId</code>, the <code>makeIterator</code> function and the <code>StorageLevel</code>).</p> <p><code>getOrElseUpdate</code> branches off per the result.</p> <p>For <code>None</code>, <code>getOrElseUpdate</code> &lt;<getlocalvalues, getlocalvalues>&gt; for the <code>BlockId</code> and eventually returns the <code>BlockResult</code> (unless terminated by a <code>SparkException</code> due to some internal error).</p> <p>For <code>Some(iter)</code>, <code>getOrElseUpdate</code> returns an iterator of <code>T</code> values.</p> <p>NOTE: <code>getOrElseUpdate</code> is used exclusively when <code>RDD</code> is requested to xref:rdd:RDD.adoc#getOrCompute[get or compute an RDD partition] (for a <code>RDDBlockId</code> with a RDD ID and a partition index).</p> <p>== [[doPutIterator]] doPutIterator Internal Method</p> <h2 id=source-scala_37>[source, scala]<a class=headerlink href=#source-scala_37 title="Permanent link">&para;</a></h2> <p>doPutIterator<a href="blockId: BlockId,
  iterator: () => Iterator[T],
  level: StorageLevel,
  classTag: ClassTag[T],
  tellMaster: Boolean = true,
  keepReadLock: Boolean = false">T</a>: Option[PartiallyUnrolledIterator[T]]</p> <hr> <p><code>doPutIterator</code> simply &lt;<doput, doput>&gt; with the <code>putBody</code> function that accepts a <code>BlockInfo</code> and does the following:</p> <p>. <code>putBody</code> branches off per whether the <code>StorageLevel</code> indicates to use a xref:storage:StorageLevel.adoc#useMemory[memory] or simply a xref:storage:StorageLevel.adoc#useDisk[disk], i.e.</p> <ul> <li> <p>When the input <code>StorageLevel</code> indicates to xref:storage:StorageLevel.adoc#useMemory[use a memory] for storage in xref:storage:StorageLevel.adoc#deserialized[deserialized] format, <code>putBody</code> requests &lt;<memorystore, memorystore>&gt; to xref:storage:MemoryStore.adoc#putIteratorAsValues[putIteratorAsValues] (for the <code>BlockId</code> and with the <code>iterator</code> factory function). + If the &lt;<memorystore, memorystore>&gt; returned a correct value, the internal <code>size</code> is set to the value. + If however the &lt;<memorystore, memorystore>&gt; failed to give a correct value, FIXME</p> </li> <li> <p>When the input <code>StorageLevel</code> indicates to xref:storage:StorageLevel.adoc#useMemory[use memory] for storage in xref:storage:StorageLevel.adoc#deserialized[serialized] format, <code>putBody</code>...FIXME</p> </li> <li> <p>When the input <code>StorageLevel</code> does not indicate to use memory for storage but xref:storage:StorageLevel.adoc#useDisk[disk] instead, <code>putBody</code>...FIXME</p> </li> </ul> <p>. <code>putBody</code> requests the &lt;<getcurrentblockstatus, current block status>&gt;</p> <p>. Only when the block was successfully stored in either the memory or disk store:</p> <ul> <li> <p><code>putBody</code> &lt;<reportblockstatus, reports the block status>&gt; to the &lt;<master, blockmanagermaster>&gt; when the input <code>tellMaster</code> flag (default: enabled) and the <code>tellMaster</code> flag of the block info are both enabled.</p> </li> <li> <p><code>putBody</code> &lt;<addupdatedblockstatustotaskmetrics, addupdatedblockstatustotaskmetrics>&gt; (with the <code>BlockId</code> and <code>BlockStatus</code>)</p> </li> <li> <p><code>putBody</code> prints out the following DEBUG message to the logs: + <div class=highlight><pre><span></span><code>Put block [blockId] locally took [time] ms
</code></pre></div></p> </li> <li> <p>When the input <code>StorageLevel</code> indicates to use xref:storage:StorageLevel.adoc#replication[replication], <code>putBody</code> &lt;<dogetlocalbytes, dogetlocalbytes>&gt; followed by &lt;<replicate, replicate>&gt; (with the input <code>BlockId</code> and the <code>StorageLevel</code> as well as the <code>BlockData</code> to replicate)</p> </li> <li> <p>With a successful replication, <code>putBody</code> prints out the following DEBUG message to the logs: + <div class=highlight><pre><span></span><code>Put block [blockId] remotely took [time] ms
</code></pre></div></p> </li> </ul> <p>. In the end, <code>putBody</code> may or may not give a <code>PartiallyUnrolledIterator</code> if...FIXME</p> <p>NOTE: <code>doPutIterator</code> is used when BlockManager is requested to &lt;<getorelseupdate, get a block from block managers or computing and storing it otherwise>&gt; and &lt;<putiterator, putiterator>&gt;.</p> <p>== [[dropFromMemory]] Dropping Block from Memory</p> <h2 id=sourcescala_4>[source,scala]<a class=headerlink href=#sourcescala_4 title="Permanent link">&para;</a></h2> <p>dropFromMemory( blockId: BlockId, data: () =&gt; Either[Array[T], ChunkedByteBuffer]): StorageLevel</p> <hr> <p>dropFromMemory prints out the following INFO message to the logs:</p> <h2 id=sourceplaintext_5>[source,plaintext]<a class=headerlink href=#sourceplaintext_5 title="Permanent link">&para;</a></h2> <h2 id=dropping-block-blockid-from-memory>Dropping block [blockId] from memory<a class=headerlink href=#dropping-block-blockid-from-memory title="Permanent link">&para;</a></h2> <p>dropFromMemory then asserts that the given block is xref:storage:BlockInfoManager.adoc#assertBlockIsLockedForWriting[locked for writing].</p> <p>If the block's xref:storage:StorageLevel.adoc[StorageLevel] uses disks and the internal xref:DiskStore.adoc[DiskStore] object (<code>diskStore</code>) does not contain the block, it is saved then. You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Writing block [blockId] to disk
</code></pre></div> <p>CAUTION: FIXME Describe the case with saving a block to disk.</p> <p>The block's memory size is fetched and recorded (using <code>MemoryStore.getSize</code>).</p> <p>The block is xref:storage:MemoryStore.adoc#remove[removed from memory] if exists. If not, you should see the following WARN message in the logs:</p> <div class=highlight><pre><span></span><code>Block [blockId] could not be dropped from memory as it does not exist
</code></pre></div> <p>It then &lt;<getcurrentblockstatus, calculates the current storage status of the block>&gt; and &lt;<reportblockstatus, reports it to the driver>&gt;. It only happens when <code>info.tellMaster</code>.</p> <p>CAUTION: FIXME When would <code>info.tellMaster</code> be <code>true</code>?</p> <p>A block is considered updated when it was written to disk or removed from memory or both. If either happened, the xref:executor:TaskMetrics.adoc#incUpdatedBlockStatuses[current TaskContext metrics are updated with the change].</p> <p>In the end, dropFromMemory returns the current storage level of the block.</p> <p>dropFromMemory is part of the xref:storage:BlockEvictionHandler.adoc#dropFromMemory[BlockEvictionHandler] abstraction.</p> <p>== [[handleLocalReadFailure]] <code>handleLocalReadFailure</code> Internal Method</p> <h2 id=source-scala_38>[source, scala]<a class=headerlink href=#source-scala_38 title="Permanent link">&para;</a></h2> <h2 id=handlelocalreadfailureblockid-blockid-nothing>handleLocalReadFailure(blockId: BlockId): Nothing<a class=headerlink href=#handlelocalreadfailureblockid-blockid-nothing title="Permanent link">&para;</a></h2> <p><code>handleLocalReadFailure</code>...FIXME</p> <p>NOTE: <code>handleLocalReadFailure</code> is used when...FIXME</p> <p>== [[releaseLockAndDispose]] releaseLockAndDispose Method</p> <h2 id=source-scala_39>[source, scala]<a class=headerlink href=#source-scala_39 title="Permanent link">&para;</a></h2> <p>releaseLockAndDispose( blockId: BlockId, data: BlockData, taskAttemptId: Option[Long] = None): Unit</p> <hr> <p>releaseLockAndDispose...FIXME</p> <p>releaseLockAndDispose is used when...FIXME</p> <p>== [[releaseLock]] releaseLock Method</p> <h2 id=source-scala_40>[source, scala]<a class=headerlink href=#source-scala_40 title="Permanent link">&para;</a></h2> <p>releaseLock( blockId: BlockId, taskAttemptId: Option[Long] = None): Unit</p> <hr> <p>releaseLock requests the &lt;<blockinfomanager, blockinfomanager>&gt; to xref:storage:BlockInfoManager.adoc#unlock[unlock the given block].</p> <p>releaseLock is part of the xref:storage:BlockDataManager.adoc#releaseLock[BlockDataManager] abstraction.</p> <p>== [[putBlockDataAsStream]] putBlockDataAsStream Method</p> <h2 id=sourcescala_5>[source,scala]<a class=headerlink href=#sourcescala_5 title="Permanent link">&para;</a></h2> <p>putBlockDataAsStream( blockId: BlockId, level: StorageLevel, classTag: ClassTag[_]): StreamCallbackWithID</p> <hr> <p>putBlockDataAsStream...FIXME</p> <p>putBlockDataAsStream is part of the xref:storage:BlockDataManager.adoc#putBlockDataAsStream[BlockDataManager] abstraction.</p> <p>== [[downgradeLock]] downgradeLock Method</p> <h2 id=source-scala_41>[source, scala]<a class=headerlink href=#source-scala_41 title="Permanent link">&para;</a></h2> <p>downgradeLock( blockId: BlockId): Unit</p> <hr> <p>downgradeLock requests the &lt;<blockinfomanager, blockinfomanager>&gt; to xref:storage:BlockInfoManager.adoc#downgradeLock[downgradeLock] for the given xref:storage:BlockId.adoc[block].</p> <p>downgradeLock seems <em>not</em> to be used.</p> <p>== [[blockIdsToLocations]] blockIdsToLocations Utility</p> <h2 id=sourcescala_6>[source,scala]<a class=headerlink href=#sourcescala_6 title="Permanent link">&para;</a></h2> <p>blockIdsToLocations( blockIds: Array[BlockId], env: SparkEnv, blockManagerMaster: BlockManagerMaster = null): Map[BlockId, Seq[String]]</p> <hr> <p>blockIdsToLocations...FIXME</p> <p>blockIdsToLocations is used in the <em>now defunct</em> Spark Streaming (when BlockRDD is requested for _locations).</p> <p>=== [[getLocationBlockIds]] getLocationBlockIds Internal Method</p> <h2 id=sourcescala_7>[source,scala]<a class=headerlink href=#sourcescala_7 title="Permanent link">&para;</a></h2> <p>getLocationBlockIds( blockIds: Array[BlockId]): Array[Seq[BlockManagerId]]</p> <hr> <p>getLocationBlockIds...FIXME</p> <p>getLocationBlockIds is used when BlockManager utility is requested to &lt;<blockidstolocations, blockidstolocations>&gt; (for the <em>now defunct</em> Spark Streaming).</p> <p>== [[logging]] Logging</p> <p>Enable <code>ALL</code> logging level for <code>org.apache.spark.storage.BlockManager</code> logger to see what happens inside.</p> <p>Add the following line to <code>conf/log4j.properties</code>:</p> <h2 id=sourceplaintext_6>[source,plaintext]<a class=headerlink href=#sourceplaintext_6 title="Permanent link">&para;</a></h2> <h2 id=log4jloggerorgapachesparkstorageblockmanagerall>log4j.logger.org.apache.spark.storage.BlockManager=ALL<a class=headerlink href=#log4jloggerorgapachesparkstorageblockmanagerall title="Permanent link">&para;</a></h2> <p>Refer to xref:ROOT:spark-logging.adoc[Logging].</p> <p>== [[internal-properties]] Internal Properties</p> <p>=== [[maxMemory]] Maximum Memory</p> <p>Total maximum value that BlockManager can ever possibly use (that depends on &lt;<memorymanager, memorymanager>&gt; and may vary over time).</p> <p>Total available xref:memory:MemoryManager.adoc#maxOnHeapStorageMemory[on-heap] and xref:memory:MemoryManager.adoc#maxOffHeapStorageMemory[off-heap] memory for storage (in bytes)</p> <p>=== [[maxOffHeapMemory]] Maximum Off-Heap Memory</p> <p>=== [[maxOnHeapMemory]] Maximum On-Heap Memory</p> <hr> <div class=md-source-date> <small> Last update: 2020-10-06 </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../../scheduler/DAGScheduler/ class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> DAGScheduler </div> </div> </a> <a href=../BlockManagerId/ class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> BlockManagerId </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener>Jacek Laskowski</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/vendor.77e55a48.min.js></script> <script src=../../assets/javascripts/bundle.9554a270.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "../..",
          features: ['navigation.tabs', 'navigation.instant'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>